{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPtlGFXLZY+njdFQhoefpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lolotta/SleepTechWordDetection/blob/master/Sleep_HTR_david_doesnt_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the IAM online Dataset\n",
        "\n",
        "!wget -q https://git.io/J0fjL -O IAM_Words.zip\n",
        "!unzip -qq IAM_Words.zip\n",
        "!mkdir data\n",
        "!mkdir data/words\n",
        "!tar -xf IAM_Words/words.tgz -C data/words\n",
        "!mv IAM_Words/words.txt data"
      ],
      "metadata": {
        "id": "4JeJ3228F_TG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdb2c89-e8a9-4020-ebc2-ef3dd9853e82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "[IAM_Words.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of IAM_Words.zip or\n",
            "        IAM_Words.zip.zip, and cannot find IAM_Words.zip.ZIP, period.\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/words’: File exists\n",
            "mv: cannot stat 'IAM_Words/words.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tf-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z7H5GzV2Lk2l",
        "outputId": "5ccc6c34-7169-41f7-cb7b-0a0e81f06455"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.12.0.dev20230101-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 563.7 MB 12 kB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (0.3.25)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.51.1)\n",
            "Collecting tf-estimator-nightly~=2.12.0.dev\n",
            "  Downloading tf_estimator_nightly-2.12.0.dev2023010109-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 82.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (0.28.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (3.19.6)\n",
            "Collecting keras-nightly~=2.12.0.dev\n",
            "  Downloading keras_nightly-2.12.0.dev2023010108-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 65.5 MB/s \n",
            "\u001b[?25hCollecting tb-nightly~=2.12.0.a\n",
            "  Downloading tb_nightly-2.12.0a20230101-py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (4.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.20 in /usr/local/lib/python3.8/dist-packages (from tf-nightly) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.38.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.15->tf-nightly) (1.7.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly~=2.12.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.12.0.a->tf-nightly) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.12.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.12.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.12.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tb-nightly~=2.12.0.a->tf-nightly) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.12.0.a->tf-nightly) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.12.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.12.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.12.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.12.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.12.0.a->tf-nightly) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.12.0.a->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tf-nightly) (3.0.9)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-nightly, flatbuffers, tf-nightly\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.12.6 keras-nightly-2.12.0.dev2023010108 tb-nightly-2.12.0a20230101 tf-estimator-nightly-2.12.0.dev2023010109 tf-nightly-2.12.0.dev20230101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "v4wXwMyz82w9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ec7261-6437-4b51-84ca-8130f8a19de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 86810\n",
            "Total validation samples: 4823\n",
            "Total test samples: 4823\n",
            "Maximum length:  21\n",
            "Vocab size:  78\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAveragePooling2D, AbstractRNNCell, MaxPooling2D, Reshape, Dropout\n",
        "from keras.initializers import Orthogonal\n",
        "import tqdm\n",
        "\n",
        "#Make a list of all the words without Comments or errored words\n",
        "base_path = \"data\"\n",
        "words_list = []\n",
        "\n",
        "words = open(f\"{base_path}/words.txt\", \"r\").readlines()\n",
        "for line in words:\n",
        "    if line[0] == \"#\":\n",
        "        continue\n",
        "    if line.split(\" \")[1] != \"err\":  # We don't need to deal with errored entries.\n",
        "        words_list.append(line)\n",
        "\n",
        "#Shuffle the word list\n",
        "np.random.shuffle(words_list)\n",
        "\n",
        "#Split the data into train, test, validation\n",
        "split_idx = int(0.9 * len(words_list))\n",
        "train_samples = words_list[:split_idx]\n",
        "test_samples = words_list[split_idx:]\n",
        "\n",
        "val_split_idx = int(0.5 * len(test_samples))\n",
        "validation_samples = test_samples[:val_split_idx]\n",
        "test_samples = test_samples[val_split_idx:]\n",
        "\n",
        "#Check if diving was clean (no data was left out)\n",
        "assert len(words_list) == len(train_samples) + len(validation_samples) + len(\n",
        "    test_samples\n",
        ")\n",
        "\n",
        "print(f\"Total training samples: {len(train_samples)}\")\n",
        "print(f\"Total validation samples: {len(validation_samples)}\")\n",
        "print(f\"Total test samples: {len(test_samples)}\")\n",
        "\n",
        "#Pipeline for data input\n",
        "    #prepare image paths\n",
        "base_image_path = os.path.join(base_path, \"words\")\n",
        "\n",
        "def get_image_paths_and_labels(samples):\n",
        "    paths = []\n",
        "    corrected_samples = []\n",
        "    for (i, file_line) in enumerate(samples):\n",
        "        line_split = file_line.strip()\n",
        "        line_split = line_split.split(\" \")\n",
        "\n",
        "        # Each line split will have this format for the corresponding image:\n",
        "        # part1/part1-part2/part1-part2-part3.png\n",
        "        image_name = line_split[0]\n",
        "        partI = image_name.split(\"-\")[0]\n",
        "        partII = image_name.split(\"-\")[1]\n",
        "        img_path = os.path.join(\n",
        "            base_image_path, partI, partI + \"-\" + partII, image_name + \".png\"\n",
        "        )\n",
        "        if os.path.getsize(img_path):\n",
        "            paths.append(img_path)\n",
        "            corrected_samples.append(file_line.split(\"\\n\")[0])\n",
        "\n",
        "    return paths, corrected_samples\n",
        "\n",
        "\n",
        "train_img_paths, train_labels = get_image_paths_and_labels(train_samples)\n",
        "validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\n",
        "test_img_paths, test_labels = get_image_paths_and_labels(test_samples)\n",
        "\n",
        "    #prepare labels\n",
        "        # Find maximum length and the size of the vocabulary in the training data.\n",
        "train_labels_cleaned = []\n",
        "            #a set includes only distinct features\n",
        "characters = set()\n",
        "max_len = 0\n",
        "\n",
        "for label in train_labels:\n",
        "    label = label.split(\" \")[-1].strip()\n",
        "    for char in label:\n",
        "        characters.add(char)\n",
        "\n",
        "    max_len = max(max_len, len(label))\n",
        "    train_labels_cleaned.append(label)\n",
        "\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "print(\"Maximum length: \", max_len)\n",
        "print(\"Vocab size: \", len(characters))\n",
        "\n",
        "        #clean validation and test labels\n",
        "def clean_labels(labels):\n",
        "    cleaned_labels = []\n",
        "    for label in labels:\n",
        "        label = label.split(\" \")[-1].strip()\n",
        "        cleaned_labels.append(label)\n",
        "    return cleaned_labels\n",
        "\n",
        "validation_labels_cleaned = clean_labels(validation_labels)\n",
        "test_labels_cleaned = clean_labels(test_labels)\n",
        "\n",
        "#Build character Vocabulary\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    # Mapping characters to integers.\n",
        "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
        "\n",
        "    # Mapping integers back to original characters.\n",
        "num_to_char = StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n",
        "\n",
        "#Resize images for batching without distortion\n",
        "def distortion_free_resize(image, img_size):\n",
        "    w, h = img_size\n",
        "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
        "\n",
        "    # Check the amount of padding needed to be done.\n",
        "    pad_height = h - tf.shape(image)[0]\n",
        "    pad_width = w - tf.shape(image)[1]\n",
        "\n",
        "    image = tf.pad(image, paddings=[[pad_height, 0],[pad_width, 0],[0, 0],],)\n",
        "\n",
        "    image = tf.transpose(image, perm=[1, 0, 2])\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "#Applying the defined functions\n",
        "batch_size = 256\n",
        "padding_token = 99\n",
        "image_width = 128\n",
        "image_height = 32\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, 1)\n",
        "    image = distortion_free_resize(image, img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def vectorize_label(label):\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "    length = tf.shape(label)[0]\n",
        "    pad_amount = max_len - length\n",
        "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
        "    return label\n",
        "\n",
        "\n",
        "def process_images_labels(image_path, label):\n",
        "    image = preprocess_image(image_path)\n",
        "    label = vectorize_label(label)\n",
        "    return {\"image\": image, \"label\": label}\n",
        "\n",
        "\n",
        "def prepare_dataset(image_paths, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
        "        process_images_labels, num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = prepare_dataset(train_img_paths, train_labels_cleaned)\n",
        "validation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)\n",
        "test_ds = prepare_dataset(test_img_paths, test_labels_cleaned)\n",
        "\n",
        "#Implement Layer for CTC Loss\n",
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss = CTCLayer()\n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "        #Input layer for predictions later\n",
        "        #input_img = keras.Input(shape=(128, 32, 1), name=\"image\")\n",
        "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(128, 32, 1), name=\"image\")\n",
        "\n",
        "        # input conv1 = 128x32x1\n",
        "        self.conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer=\"he_normal\", name=\"Conv1\", input_shape=input_shape)\n",
        "        #ignore this\n",
        "            #if we use input layer and thus dont specify the input shape here\n",
        "        #self.conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer=\"he_normal\", name=\"Conv1\")\n",
        "        \n",
        "        # output conv1 = 128x32x32\n",
        "        self.conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer=\"he_normal\", name=\"Conv2\")\n",
        "        # output conv2 = 128x32x32\n",
        "        self.pooling1 = MaxPooling2D((2,2), name=\"pool1\")\n",
        "        # output pooling1 = 64x16x32\n",
        "        self.conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=\"he_normal\", name=\"Conv3\")\n",
        "        # output conv3 = 64x16x64\n",
        "        self.conv4 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=\"he_normal\", name=\"Conv4\")\n",
        "        # output conv3 = 64x16x64\n",
        "        #self.globalpooling = GlobalAveragePooling2D()\n",
        "        # output globalpooling = 64\n",
        "        self.dense1 = Dense(64, activation=\"relu\", name=\"dense1\")\n",
        "        self.dropout = Dropout(0.1)\n",
        "\n",
        "        #versteht kein mensch\n",
        "        self.globalpooling = MaxPooling2D((2,2),name=\"pool2\")\n",
        "            #output maxpooling: 32x8x64\n",
        "        new_shape = ((image_width // 4), (image_height // 4) * 64)\n",
        "        self.reshape = Reshape(target_shape=new_shape, name=\"reshape\")\n",
        "\n",
        "        #self.lstm1 = keras.layers.LSTM(64, return_sequences=True, dropout=0.15)\n",
        "        #self.lstm2 = keras.layers.LSTM(64, return_sequences=True, dropout=0.15)\n",
        "\n",
        "        #what the fuck is this really\n",
        "        self.lstm1 = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.1))\n",
        "        self.lstm2 = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.1))\n",
        "\n",
        "        self.output_layer = keras.layers.Dense(len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\")\n",
        "\n",
        "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
        "\n",
        "    #achtung absatz!!\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return self.metrics_list\n",
        "\n",
        "    def reset_metrics(self):\n",
        "        for metric in self.metrics:\n",
        "            metric.reset_state()\n",
        "\n",
        "    def call(self, x, training = False):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pooling1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.globalpooling(x)\n",
        "        x = self.reshape(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "\n",
        "        output = self.output_layer(x)\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, images, label):\n",
        "\n",
        "        with tf.GradientTape() as tape: \n",
        "            prediction = self(images, training = True)\n",
        "            loss = self.loss(label,prediction)\n",
        "\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
        "        #self.metrics[0].update_state(label, prediction)\n",
        "        self.metrics[0].update_state(loss) \n",
        "\n",
        "        return {m.name : m.result() for m in self.metrics}  \n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, images, label):\n",
        "\n",
        "        prediction = self(images, training = False)\n",
        "        loss = self.loss(label,prediction)\n",
        "        #self.metrics[0].update_state(label, prediction)\n",
        "        self.metrics[0].update_state(loss)\n",
        "\n",
        "        return {m.name : m.result() for m in self.metrics} "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_images = []\n",
        "validation_labels = []\n",
        "\n",
        "for batch in validation_ds:\n",
        "    validation_images.append(batch[\"image\"])\n",
        "    validation_labels.append(batch[\"label\"])\n",
        "\n",
        "def calculate_edit_distance(labels, predictions):\n",
        "    # Get a single batch and convert its labels to sparse tensors.\n",
        "    saprse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n",
        "\n",
        "    # Make predictions and convert them to sparse tensors.\n",
        "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
        "    predictions_decoded = keras.backend.ctc_decode(\n",
        "        predictions, input_length=input_len, greedy=True\n",
        "    )[0][0][:, :max_len]\n",
        "    sparse_predictions = tf.cast(\n",
        "        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n",
        "    )\n",
        "\n",
        "    # Compute individual edit distances and average them out.\n",
        "    edit_distances = tf.edit_distance(\n",
        "        sparse_predictions, saprse_labels, normalize=False\n",
        "    )\n",
        "    return tf.reduce_mean(edit_distances)\n",
        "\n",
        "\n",
        "class EditDistanceCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, pred_model):\n",
        "        super().__init__()\n",
        "        self.prediction_model = pred_model\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        edit_distances = []\n",
        "\n",
        "        for i in range(len(validation_images)):\n",
        "            labels = validation_labels[i]\n",
        "            predictions = self.prediction_model.predict(validation_images[i])\n",
        "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
        "\n",
        "        tf.summary.scalar('Edit Distance', data=np.mean(edit_distances), step=epoch)\n",
        "\n",
        "\n",
        "        print(\n",
        "            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "PiViTBM9EX23"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_shape=(128,32,1))\n",
        "\"\"\"\n",
        "def training_loop(model, train, test, epochs):\n",
        "\n",
        "    # Save loss and accuracy as dictionaries in a list for visualization\n",
        "    lists = []\n",
        "\n",
        "    for n in range(epochs):\n",
        "        print(f\"Epoch {n}:\")\n",
        "\n",
        "        for data in tqdm.tqdm(train, position=0, leave=True):\n",
        "            images  = data[\"image\"]\n",
        "            labels  = data[\"label\"]\n",
        "            metrics = model.train_step(images, labels)\n",
        "\n",
        "        # Add metrics to list\n",
        "        lists.append(metrics)\n",
        "        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
        "        model.reset_metrics()\n",
        "\n",
        "        for data in tqdm.tqdm(test, position=0, leave=True):\n",
        "            images  = data[\"image\"]\n",
        "            labels  = data[\"label\"]\n",
        "            metrics = model.test_step(images, labels)\n",
        "\n",
        "        # Add metrics to list\n",
        "        lists.append(metrics)\n",
        "        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
        "        model.reset_metrics()\n",
        "        \n",
        "    return lists\n",
        "\n",
        "li = training_loop(model, train_ds, test_ds, epochs=15)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0apc7rDYkyNE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8c08acfc-9832-465c-a114-1ce1e775195e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef training_loop(model, train, test, epochs):\\n\\n    # Save loss and accuracy as dictionaries in a list for visualization\\n    lists = []\\n\\n    for n in range(epochs):\\n        print(f\"Epoch {n}:\")\\n\\n        for data in tqdm.tqdm(train, position=0, leave=True):\\n            images  = data[\"image\"]\\n            labels  = data[\"label\"]\\n            metrics = model.train_step(images, labels)\\n\\n        # Add metrics to list\\n        lists.append(metrics)\\n        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\\n        model.reset_metrics()\\n\\n        for data in tqdm.tqdm(test, position=0, leave=True):\\n            images  = data[\"image\"]\\n            labels  = data[\"label\"]\\n            metrics = model.test_step(images, labels)\\n\\n        # Add metrics to list\\n        lists.append(metrics)\\n        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\\n        model.reset_metrics()\\n        \\n    return lists\\n\\nli = training_loop(model, train_ds, test_ds, epochs=15)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction_model = model.predict()\n",
        "prediction_model = keras.models.Model(inputs = model.get_layer(name=\"image\").input, outputs = model.get_layer(name=\"dense2\").output)\n",
        "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
        "\n",
        "logdir = \"logs/wordRec/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[tensorboard_callback, edit_distance_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "-MGXBbvNFRbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "f10f7040-4940-4f72-d3b6-66e808ba4d1f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-64f70fa47413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#prediction_model = model.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0medit_distance_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEditDistanceCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logs/wordRec/scalars/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mmask\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m         \"\"\"\n\u001b[1;32m   1912\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Layer dense2 has no inbound nodes."
          ]
        }
      ]
    }
  ]
}